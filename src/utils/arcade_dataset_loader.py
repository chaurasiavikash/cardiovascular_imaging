#!/usr/bin/env python3
"""
ARCADE Dataset Loader - Updated for Real Downloaded Structure
Handles both stenosis detection and vessel segmentation (syntax) tasks

Your Dataset Structure:
arcade/
‚îú‚îÄ‚îÄ stenosis/     # Stenosis detection task
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ val/
‚îÇ   ‚îî‚îÄ‚îÄ test/
‚îî‚îÄ‚îÄ syntax/       # Vessel segmentation task  
    ‚îú‚îÄ‚îÄ train/
    ‚îú‚îÄ‚îÄ val/
    ‚îî‚îÄ‚îÄ test/
"""

import numpy as np
import json
import cv2
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import logging
from PIL import Image
import matplotlib.pyplot as plt


class ARCADEDatasetLoader:
    """
    Loader for ARCADE coronary artery dataset with your exact structure.
    
    Supports both tasks:
    - stenosis: Stenosis detection/classification
    - syntax: Vessel segmentation (syntax = vessel structure)
    """
    
    def __init__(self, task_type: str = "syntax"):
        """
        Initialize ARCADE dataset loader.
        
        Args:
            task_type: "syntax" for vessel segmentation or "stenosis" for stenosis detection
        """
        self.logger = logging.getLogger(__name__)
        self.task_type = task_type.lower()
        
        if self.task_type not in ["syntax", "stenosis"]:
            raise ValueError("task_type must be 'syntax' or 'stenosis'")
    
    def load_arcade_dataset(self, data_path: str, split: str = "train") -> Dict[str, Any]:
        """
        Load ARCADE dataset from your downloaded structure.
        
        Args:
            data_path: Path to arcade folder (e.g., "data/arcade")
            split: "train", "val", or "test"
            
        Returns:
            Dictionary with loaded imaging data and annotations
        """
        self.logger.info(f"Loading ARCADE {self.task_type} dataset from: {data_path}")
        
        arcade_root = Path(data_path)
        task_dir = arcade_root / self.task_type / split
        
        if not task_dir.exists():
            raise FileNotFoundError(f"ARCADE {self.task_type}/{split} not found at: {task_dir}")
        
        # Load annotations
        annotations_file = task_dir / "annotations" / f"{split}.json"
        images_dir = task_dir / "images"
        
        if not annotations_file.exists():
            raise FileNotFoundError(f"Annotations file not found: {annotations_file}")
        
        self.logger.info(f"Loading annotations from: {annotations_file}")
        with open(annotations_file, 'r') as f:
            coco_data = json.load(f)
        
        # Process the dataset
        if self.task_type == "syntax":
            return self._load_vessel_segmentation_data(coco_data, images_dir)
        else:  # stenosis
            return self._load_stenosis_detection_data(coco_data, images_dir)
    
    def _load_vessel_segmentation_data(self, coco_data: Dict, images_dir: Path) -> Dict[str, Any]:
        """Load vessel segmentation data for validation pipeline."""
        self.logger.info("Processing vessel segmentation (syntax) data...")
        
        # Extract image and annotation info
        images_info = {img['id']: img for img in coco_data['images']}
        annotations = coco_data['annotations']
        
        ground_truth_masks = []
        prediction_masks = []
        patient_metadata = []
        
        # Group annotations by image
        image_annotations = {}
        for ann in annotations:
            image_id = ann['image_id']
            if image_id not in image_annotations:
                image_annotations[image_id] = []
            image_annotations[image_id].append(ann)
        
        self.logger.info(f"Processing {len(image_annotations)} images with annotations...")
        
        for image_id, anns in image_annotations.items():
            if image_id not in images_info:
                continue
                
            image_info = images_info[image_id]
            image_path = images_dir / image_info['file_name']
            
            if not image_path.exists():
                self.logger.warning(f"Image not found: {image_path}")
                continue
            
            # Load image to get dimensions
            try:
                with Image.open(image_path) as img:
                    width, height = img.size
            except Exception as e:
                self.logger.warning(f"Failed to load image {image_path}: {e}")
                continue
            
            # Create combined mask for all vessels in this image
            combined_mask = np.zeros((height, width), dtype=np.uint8)
            
            for ann in anns:
                # Convert COCO segmentation to mask
                mask = self._coco_segmentation_to_mask(
                    ann['segmentation'], height, width
                )
                combined_mask = np.maximum(combined_mask, mask)
            
            # Only process images that have vessel annotations
            if np.sum(combined_mask) == 0:
                continue
            
            # Create simulated prediction (with realistic errors)
            pred_mask = self._simulate_algorithm_prediction(combined_mask)
            
            ground_truth_masks.append(combined_mask)
            prediction_masks.append(pred_mask)
            
            # Extract metadata
            metadata = {
                'patient_id': f"arcade_syntax_{image_id}",
                'image_filename': image_info['file_name'],
                'image_shape': combined_mask.shape,
                'dataset': 'ARCADE_Syntax',
                'modality': 'X-ray_angiography',
                'num_vessels': len(anns),
                'vessel_area': float(np.sum(combined_mask))
            }
            patient_metadata.append(metadata)
            
            if len(ground_truth_masks) % 50 == 0:
                self.logger.info(f"Processed {len(ground_truth_masks)} images...")
        
        self.logger.info(f"Successfully loaded {len(ground_truth_masks)} vessel segmentation images")
        
        # Generate demographics and clinical data
        demographics = self._generate_realistic_demographics(len(ground_truth_masks))
        clinical_data = self._extract_clinical_measurements_2d(ground_truth_masks, patient_metadata)
        
        return {
            'ground_truth': ground_truth_masks,
            'predictions': prediction_masks,
            'demographics': demographics,
            'clinical_data': clinical_data,
            'metadata': {
                'n_samples': len(ground_truth_masks),
                'dataset_name': 'ARCADE_Vessel_Segmentation',
                'data_source': 'real_medical_imaging',
                'patient_metadata': patient_metadata,
                'task_type': 'vessel_segmentation'
            }
        }
    
    def _load_stenosis_detection_data(self, coco_data: Dict, images_dir: Path) -> Dict[str, Any]:
        """Load stenosis detection data for validation pipeline."""
        self.logger.info("Processing stenosis detection data...")
        
        images_info = {img['id']: img for img in coco_data['images']}
        annotations = coco_data['annotations']
        
        ground_truth_stenosis = []
        predicted_stenosis = []
        patient_metadata = []
        
        # Group annotations by image for stenosis detection
        image_annotations = {}
        for ann in annotations:
            image_id = ann['image_id']
            if image_id not in image_annotations:
                image_annotations[image_id] = []
            image_annotations[image_id].append(ann)
        
        self.logger.info(f"Processing {len(image_annotations)} images for stenosis detection...")
        
        for image_id, anns in image_annotations.items():
            if image_id not in images_info:
                continue
                
            image_info = images_info[image_id]
            
            # Extract stenosis severity from annotations
            # In ARCADE, stenosis severity might be encoded in category_id or custom fields
            stenosis_severity = self._extract_stenosis_severity(anns)
            
            # Create simulated prediction with some error
            pred_severity = stenosis_severity + np.random.normal(0, 5)  # Add 5% std error
            pred_severity = np.clip(pred_severity, 0, 100)
            
            ground_truth_stenosis.append(stenosis_severity)
            predicted_stenosis.append(pred_severity)
            
            # Extract metadata
            metadata = {
                'patient_id': f"arcade_stenosis_{image_id}",
                'image_filename': image_info['file_name'],
                'dataset': 'ARCADE_Stenosis',
                'modality': 'X-ray_angiography',
                'num_stenoses': len(anns)
            }
            patient_metadata.append(metadata)
        
        self.logger.info(f"Successfully loaded {len(ground_truth_stenosis)} stenosis measurements")
        
        # Generate demographics and clinical data
        demographics = self._generate_realistic_demographics(len(ground_truth_stenosis))
        clinical_data = self._extract_stenosis_clinical_data(ground_truth_stenosis, patient_metadata)
        
        return {
            'ground_truth': np.array(ground_truth_stenosis),
            'predictions': np.array(predicted_stenosis),
            'demographics': demographics,
            'clinical_data': clinical_data,
            'metadata': {
                'n_samples': len(ground_truth_stenosis),
                'dataset_name': 'ARCADE_Stenosis_Detection',
                'data_source': 'real_medical_imaging',
                'patient_metadata': patient_metadata,
                'task_type': 'stenosis_detection'
            }
        }
    
    def _coco_segmentation_to_mask(self, segmentation: List, height: int, width: int) -> np.ndarray:
        """Convert COCO segmentation to binary mask."""
        mask = np.zeros((height, width), dtype=np.uint8)
        
        for seg in segmentation:
            if isinstance(seg, list) and len(seg) >= 6:  # Polygon format
                # Reshape to pairs of coordinates
                coords = np.array(seg).reshape(-1, 2)
                # Convert to integer coordinates
                coords = coords.astype(np.int32)
                # Fill polygon
                cv2.fillPoly(mask, [coords], 1)
            elif isinstance(seg, dict) and 'counts' in seg:
                # RLE format (if pycocotools available)
                try:
                    from pycocotools import mask as coco_mask
                    binary_mask = coco_mask.decode(seg)
                    mask = np.maximum(mask, binary_mask)
                except ImportError:
                    self.logger.warning("pycocotools not available, skipping RLE segmentation")
        
        return mask
    
    def _extract_stenosis_severity(self, annotations: List[Dict]) -> float:
        """Extract stenosis severity from ARCADE annotations."""
        # ARCADE stenosis annotations might have severity in different fields
        # This is a simplified extraction - adjust based on actual annotation format
        
        if not annotations:
            return 0.0
        
        # Check for severity in custom fields
        for ann in annotations:
            # Common fields where stenosis severity might be stored
            if 'stenosis_severity' in ann:
                return float(ann['stenosis_severity'])
            elif 'severity' in ann:
                return float(ann['severity'])
            elif 'attributes' in ann and 'severity' in ann['attributes']:
                return float(ann['attributes']['severity'])
            elif 'category_id' in ann:
                # Map category_id to severity (example mapping)
                category_to_severity = {1: 0, 2: 25, 3: 50, 4: 75, 5: 100}
                return float(category_to_severity.get(ann['category_id'], 0))
        
        # If no explicit severity, estimate from bounding box area (simplified)
        total_area = sum(ann.get('area', 0) for ann in annotations)
        # Normalize area to severity percentage (this is a rough approximation)
        estimated_severity = min(100, total_area / 1000)  # Adjust scaling as needed
        
        return estimated_severity
    
    def _simulate_algorithm_prediction(self, ground_truth: np.ndarray) -> np.ndarray:
        """Create realistic algorithm prediction with typical segmentation errors."""
        prediction = ground_truth.copy()
        
        # Add boundary errors (most common in vessel segmentation)
        kernel = np.ones((3, 3), np.uint8)
        boundary = cv2.morphologyEx(ground_truth, cv2.MORPH_GRADIENT, kernel)
        
        # Random boundary noise (10% of boundary pixels)
        boundary_noise = np.random.random(ground_truth.shape) < 0.10
        prediction[boundary & boundary_noise] = 1 - prediction[boundary & boundary_noise]
        
        # Small false positives (2% rate)
        false_positive_mask = (ground_truth == 0) & (np.random.random(ground_truth.shape) < 0.02)
        prediction[false_positive_mask] = 1
        
        # Small false negatives (3% rate) 
        false_negative_mask = (ground_truth == 1) & (np.random.random(ground_truth.shape) < 0.03)
        prediction[false_negative_mask] = 0
        
        # Apply small morphological operations to make it more realistic
        prediction = cv2.morphologyEx(prediction, cv2.MORPH_CLOSE, np.ones((2,2), np.uint8))
        
        return prediction
    
    def _generate_realistic_demographics(self, n_patients: int) -> Dict[str, List]:
        """Generate realistic cardiovascular patient demographics."""
        np.random.seed(42)
        
        return {
            'age_group': np.random.choice(['young', 'middle', 'elderly'], n_patients, p=[0.1, 0.3, 0.6]).tolist(),
            'sex': np.random.choice(['male', 'female'], n_patients, p=[0.65, 0.35]).tolist(),
            'race': np.random.choice(['white', 'black', 'asian', 'hispanic'], n_patients, p=[0.6, 0.2, 0.15, 0.05]).tolist(),
            'institution': np.random.choice(['site_a', 'site_b', 'site_c'], n_patients, p=[0.4, 0.35, 0.25]).tolist()
        }
    
    def _extract_clinical_measurements_2d(self, segmentations: List[np.ndarray], 
                                        metadata: List[Dict]) -> Dict[str, List]:
        """Extract clinical measurements from vessel segmentations."""
        vessel_areas = []
        vessel_complexities = []
        stenosis_estimates = []
        
        for seg, meta in zip(segmentations, metadata):
            # Vessel area (converted to mm¬≤ assuming typical pixel spacing)
            area_pixels = np.sum(seg > 0)
            # Assume 0.3mm/pixel (typical for coronary angiography)
            area_mm2 = area_pixels * (0.3 ** 2)
            vessel_areas.append(area_mm2)
            
            # Vessel complexity (perimeter to area ratio)
            if area_pixels > 0:
                perimeter = self._calculate_perimeter(seg)
                complexity = perimeter / np.sqrt(area_pixels) if area_pixels > 0 else 0
                vessel_complexities.append(complexity)
                
                # Estimate stenosis from vessel width variation
                stenosis_est = self._estimate_stenosis_from_segmentation(seg)
                stenosis_estimates.append(stenosis_est)
            else:
                vessel_complexities.append(0.0)
                stenosis_estimates.append(0.0)
        
        return {
            'vessel_area_mm2': vessel_areas,
            'vessel_complexity': vessel_complexities,
            'estimated_stenosis_percent': stenosis_estimates,
            'vessel_length_mm': [area/2 for area in vessel_areas]  # Rough length estimate
        }
    
    def _extract_stenosis_clinical_data(self, stenosis_values: List[float], 
                                      metadata: List[Dict]) -> Dict[str, List]:
        """Extract clinical data for stenosis detection task."""
        return {
            'stenosis_severity_percent': stenosis_values,
            'vessel_segment': [f"segment_{i%5}" for i in range(len(stenosis_values))],
            'calcium_score': np.random.uniform(0, 400, len(stenosis_values)).tolist(),
            'plaque_burden': [min(100, sev * 1.2) for sev in stenosis_values]
        }
    
    def _calculate_perimeter(self, binary_mask: np.ndarray) -> float:
        """Calculate vessel perimeter."""
        kernel = np.ones((3, 3), np.uint8)
        boundary = cv2.morphologyEx(binary_mask.astype(np.uint8), cv2.MORPH_GRADIENT, kernel)
        return float(np.sum(boundary > 0))
    
    def _estimate_stenosis_from_segmentation(self, vessel_mask: np.ndarray) -> float:
        """Estimate stenosis severity from vessel segmentation."""
        if np.sum(vessel_mask) == 0:
            return 0.0
        
        # Simple stenosis estimation based on diameter variation
        from scipy import ndimage
        
        # Get vessel skeleton
        from skimage import morphology
        skeleton = morphology.skeletonize(vessel_mask > 0)
        
        if np.any(skeleton):
            # Calculate distance transform (vessel radii)
            dist_transform = ndimage.distance_transform_edt(vessel_mask)
            skeleton_coords = np.where(skeleton)
            
            if len(skeleton_coords[0]) > 5:  # Need enough points
                radii = dist_transform[skeleton_coords]
                
                # Calculate stenosis as percentage reduction from max radius
                max_radius = np.max(radii)
                min_radius = np.min(radii)
                
                if max_radius > 0:
                    stenosis_percent = ((max_radius - min_radius) / max_radius) * 100
                    return min(100, max(0, stenosis_percent))
        
        return 0.0
    
    def visualize_sample(self, dataset: Dict[str, Any], sample_idx: int = 0, save_path: Optional[str] = None):
        """Visualize a sample from the dataset for verification."""
        if sample_idx >= len(dataset['ground_truth']):
            print(f"Sample index {sample_idx} out of range")
            return
        
        gt = dataset['ground_truth'][sample_idx]
        pred = dataset['predictions'][sample_idx]
        metadata = dataset['metadata']['patient_metadata'][sample_idx]
        
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # Ground truth
        axes[0].imshow(gt, cmap='gray')
        axes[0].set_title(f"Ground Truth\n{metadata['image_filename']}")
        axes[0].axis('off')
        
        # Prediction
        axes[1].imshow(pred, cmap='gray')
        axes[1].set_title("Simulated Prediction")
        axes[1].axis('off')
        
        # Overlay
        overlay = np.zeros((*gt.shape, 3))
        overlay[gt > 0] = [0, 1, 0]  # Green for ground truth
        overlay[pred > 0] = [1, 0, 0]  # Red for prediction
        overlay[(gt > 0) & (pred > 0)] = [1, 1, 0]  # Yellow for overlap
        
        axes[2].imshow(overlay)
        axes[2].set_title("Overlay (GT=Green, Pred=Red, Overlap=Yellow)")
        axes[2].axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"Visualization saved to: {save_path}")
        
        plt.show()
        
        # Print metadata
        print(f"\nSample Metadata:")
        for key, value in metadata.items():
            print(f"  {key}: {value}")


def test_arcade_loader():
    """Test the ARCADE dataset loader with your data structure."""
    print("üß™ Testing ARCADE Dataset Loader")
    print("=" * 40)
    
    # Test vessel segmentation (syntax)
    try:
        loader = ARCADEDatasetLoader("syntax")
        data = loader.load_arcade_dataset("data/arcade", "train")
        
        print(f"‚úÖ Vessel Segmentation: {data['metadata']['n_samples']} samples loaded")
        print(f"   Sample shape: {data['ground_truth'][0].shape}")
        
        # Visualize first sample
        loader.visualize_sample(data, 0)
        
    except Exception as e:
        print(f"‚ùå Vessel segmentation test failed: {e}")
    
    # Test stenosis detection
    try:
        loader = ARCADEDatasetLoader("stenosis")
        data = loader.load_arcade_dataset("data/arcade", "train")
        
        print(f"‚úÖ Stenosis Detection: {data['metadata']['n_samples']} samples loaded")
        
    except Exception as e:
        print(f"‚ùå Stenosis detection test failed: {e}")


if __name__ == "__main__":
    test_arcade_loader()